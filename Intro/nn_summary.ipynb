{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Networks Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "n_cols = data.shape[1]\n",
    "model.add(Dense(5, activation='relu', input_shape=(n_cols, )))  # input shape has to be the same as number of columns\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))  # output layer\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_square_error') \n",
    "# adam is more effcicient than gradient descent.\n",
    "# it adapts the learning rate automatically\n",
    "\n",
    "model.fit(predictors, target)\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "n_cols = data.shape[1]\n",
    "target = to_categorical(target)\n",
    "\n",
    "model.add(Dense(5, activation='relu', input_shape=(n_cols, ))) \n",
    "model.add(Dropout(0.2))  # dropout is a regularization technique to prevent overfitting. Normally ~0.2-0.4\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "# for classification the last layer has an activation function which ussually is softmax\n",
    "# in addition, the output dimension has to be the same as the calsses in the target\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])  # to measure accuracy in classification\n",
    "\n",
    "model.fit(predictors, target, \n",
    "          epochs=20,  # number of iterations\n",
    "          batch_size=50,  # size of the splitted bachs (this only works with SGD?)\n",
    "          validation_split=0.2, )\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNN) - supervised\n",
    "\n",
    "This are mainly use for images as they reduce dimensionality. Check this [link](https://courses.edx.org/courses/course-v1:IBM+DL0101EN+3T2019/courseware/89227024130b43f684d95376901b65c8/052a444d45914712a597f0c58cbc4391/?child=first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = (N, N, 3)  # 3 for RGB images and 1 for gray scale images\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(2, 2),  # size of the filter to use\n",
    "                 strides=(1, 1),  # steps the filter is moved\n",
    "                 activation='relu', \n",
    "                 input_shape=input_shape)) \n",
    "model.add(MaxPool2D(pool_size(2, 2),  strides=(1, 1))\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), strides=(1, 1), activation='relu') \n",
    "model.add(MaxPool2D(pool_size(2, 2))  \n",
    "model.add(Flatten())  # so the data can proceed to the fully-connected layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='sotmax'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])  # to measure accuracy in classification\n",
    "\n",
    "model.fit(predictors, target)\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN)  - supervised\n",
    "\n",
    "This are networks with loops that take into account dependency of data like images in a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders  - unsupervised\n",
    "\n",
    "These commpress and decompress functions learned from data. For this reason they are data-specific.\n",
    "\n",
    "These are used in data de-noising and dimensionality reduction for data visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
